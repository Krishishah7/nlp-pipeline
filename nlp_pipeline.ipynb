{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgS9KeRp8Eo1thHAKfsv/d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krishishah7/nlp-pipeline/blob/main/nlp_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mini NLP Pipeline\n",
        "\n",
        "This notebook demonstrates an end-to-end NLP pipeline that processes raw text through preprocessing, POS tagging, word frequency analysis, and sentiment analysis.\n"
      ],
      "metadata": {
        "id": "qPfgIOPJgVAU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO4pzwf3gLJ-",
        "outputId": "5da193d1-6c47-47c4-d365-64a221e51661"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('vader_lexicon')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "Natural Language Processing is very useful for analyzing text data.\n",
        "However, it can sometimes be challenging and complex.\n",
        "\"\"\"\n",
        "print(\"Original Text:\\n\", text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1eBUC2Cgiqw",
        "outputId": "1e28f45a-e2cb-4443-bf15-e341ee3f0732"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            " \n",
            "Natural Language Processing is very useful for analyzing text data.\n",
            "However, it can sometimes be challenging and complex.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Preprocessing"
      ],
      "metadata": {
        "id": "CZ6CHthuhN-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lowercase\n",
        "text = text.lower()\n",
        "\n",
        "# Remove punctuation\n",
        "text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "# Tokenization\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Remove stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "print(\"Preprocessed Tokens:\\n\", filtered_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDfyOXhDgpt7",
        "outputId": "7a153ad5-cfef-4a7d-fbfc-063ba03efcf2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed Tokens:\n",
            " ['natural', 'language', 'processing', 'useful', 'analyzing', 'text', 'data', 'however', 'sometimes', 'challenging', 'complex']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "POS Tagging"
      ],
      "metadata": {
        "id": "t9-RarIMhCD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_tags = nltk.pos_tag(filtered_tokens)\n",
        "\n",
        "print(\"\\nPOS Tagging:\")\n",
        "for word, tag in pos_tags:\n",
        "    print(word, \"->\", tag)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vg0oNLrngqRC",
        "outputId": "920a5e52-f3d0-49f6-da9a-44062a4a7e77"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "POS Tagging:\n",
            "natural -> JJ\n",
            "language -> NN\n",
            "processing -> NN\n",
            "useful -> JJ\n",
            "analyzing -> VBG\n",
            "text -> NN\n",
            "data -> NNS\n",
            "however -> RB\n",
            "sometimes -> RB\n",
            "challenging -> VBG\n",
            "complex -> JJ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word Frequency Analysis"
      ],
      "metadata": {
        "id": "7Qt5A-5Cg-M5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "freq_dist = FreqDist(filtered_tokens)\n",
        "\n",
        "print(\"\\nWord Frequency:\")\n",
        "for word, freq in freq_dist.items():\n",
        "    print(word, \":\", freq)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qq0rnK80gtlE",
        "outputId": "171c182f-48fe-44c8-f341-7f7dd4c3bfaa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word Frequency:\n",
            "natural : 1\n",
            "language : 1\n",
            "processing : 1\n",
            "useful : 1\n",
            "analyzing : 1\n",
            "text : 1\n",
            "data : 1\n",
            "however : 1\n",
            "sometimes : 1\n",
            "challenging : 1\n",
            "complex : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment Analysis"
      ],
      "metadata": {
        "id": "v8doVt1rg7KQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sia = SentimentIntensityAnalyzer()\n",
        "sentiment_scores = sia.polarity_scores(text)\n",
        "\n",
        "print(\"\\nSentiment Scores:\")\n",
        "print(sentiment_scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWvjXF8Pgvlk",
        "outputId": "7f9db16b-9f32-435d-ef24-a58eb87cd991"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentiment Scores:\n",
            "{'neg': 0.0, 'neu': 0.673, 'pos': 0.327, 'compound': 0.7425}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compound = sentiment_scores['compound']\n",
        "\n",
        "if compound >= 0.05:\n",
        "    sentiment = \"Positive\"\n",
        "elif compound <= -0.05:\n",
        "    sentiment = \"Negative\"\n",
        "else:\n",
        "    sentiment = \"Neutral\"\n",
        "\n",
        "print(\"Overall Sentiment:\", sentiment)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4juhR3AgzIC",
        "outputId": "05a964da-ec44-463f-af8f-ca5db1e94ee0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Sentiment: Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Pipeline Summary\n",
        "\n",
        "- Raw text was cleaned using preprocessing techniques\n",
        "- POS tagging was applied to understand grammatical structure\n",
        "- Word frequency analysis identified important terms\n",
        "- Sentiment analysis classified the overall sentiment of the text\n"
      ],
      "metadata": {
        "id": "ACmgYdEmg5FS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YQpqRFIUg2Hj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}